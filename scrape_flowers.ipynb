{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7454ff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National flowers data scraped and saved to national_flowers.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_national_flowers(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    flowers_list = []\n",
    "\n",
    "    # Find the correct table (assuming there is only one such table on the page)\n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    for row in rows[1:]:  # skip header row\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) >= 3:  # check if row contains sufficient columns\n",
    "            country = cols[0].text.strip()\n",
    "            flower = cols[1].text.strip()\n",
    "            description = cols[2].text.strip() if len(cols) > 2 else ''\n",
    "            \n",
    "            flowers_list.append({\n",
    "                'Country': country,\n",
    "                'Flower': flower,\n",
    "                'Description': description\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(flowers_list)\n",
    "\n",
    "# Usage\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_national_flowers'\n",
    "national_flowers_data = scrape_national_flowers(url)\n",
    "national_flowers_data.to_csv('national_flowers.csv', index=False)\n",
    "print('National flowers data scraped and saved to national_flowers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e233b4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State flowers data scraped and saved to us_state_flowers.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_state_flowers(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    flowers_list = []\n",
    "\n",
    "    # Find the correct table (assuming the state flowers are well structured in the page)\n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    for row in rows[1:]:  # skip header row\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) >= 2:  # check if row contains sufficient columns\n",
    "            state = cols[0].text.strip()\n",
    "            flower = cols[1].text.strip()\n",
    "            \n",
    "            flowers_list.append({\n",
    "                'State': state,\n",
    "                'Flower': flower\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(flowers_list)\n",
    "\n",
    "# Usage\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_U.S._state_and_territory_flowers'\n",
    "state_flowers_data = scrape_state_flowers(url)\n",
    "state_flowers_data.to_csv('us_state_flowers.csv', index=False)\n",
    "print('State flowers data scraped and saved to us_state_flowers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a49eff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed files saved as national_flowers_with_scientific_names.csv and state_flowers_with_scientific_names.csv.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_scientific_name(flower_name):\n",
    "    \"\"\"Fetch the scientific name of a flower from Wikipedia.\"\"\"\n",
    "    search_url = f\"https://en.wikipedia.org/wiki/{flower_name.replace(' ', '_')}\"\n",
    "    try:\n",
    "        response = requests.get(search_url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            infobox = soup.find('table', {'class': 'infobox'})\n",
    "            if infobox:\n",
    "                scientific_name = infobox.find('i')\n",
    "                if scientific_name:\n",
    "                    return scientific_name.text\n",
    "        return \"Not found\"\n",
    "    except Exception as e:\n",
    "        return \"Error\"\n",
    "\n",
    "def process_flowers(file_path, location_type):\n",
    "    \"\"\"Process flower data to add scientific names.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Flowers'] = df['Flower'].str.split(' and |,| or ')  # Split entries with multiple flowers\n",
    "    df = df.explode('Flowers').reset_index(drop=True)  # Create a new row for each flower\n",
    "    df['Flowers'] = df['Flowers'].str.strip().str.capitalize()  # Standardize capitalization\n",
    "    df['Scientific Name'] = df['Flowers'].apply(get_scientific_name)  # Get scientific names\n",
    "\n",
    "    # Drop the old Flower column and rename Flowers column back to Flower\n",
    "    df.drop('Flower', axis=1, inplace=True)\n",
    "    df.rename(columns={'Flowers': 'Flower'}, inplace=True)\n",
    "    output_path = f\"{location_type}_flowers_with_scientific_names.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    return output_path\n",
    "\n",
    "# Process each CSV\n",
    "output_national = process_flowers('national_flowers.csv', 'national')\n",
    "output_state = process_flowers('us_state_flowers.csv', 'state')\n",
    "\n",
    "print(f\"Processed files saved as {output_national} and {output_state}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992a0ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Water lily: 'NoneType' object has no attribute 'find'\n",
      "Error processing Water lily: 'NoneType' object has no attribute 'find'\n",
      "Error processing Sakura blossom: 'NoneType' object has no attribute 'find'\n",
      "Error processing Poppy: 'NoneType' object has no attribute 'find'\n",
      "Error processing Daisy: 'NoneType' object has no attribute 'find'\n",
      "Error processing Chamomile: 'NoneType' object has no attribute 'find'\n",
      "Error processing Tudor rose: 'NoneType' object has no attribute 'find'\n",
      "Error processing : 'NoneType' object has no attribute 'find'\n",
      "Error processing Others: 'NoneType' object has no attribute 'find'\n",
      "Error processing Maple leaf: 'NoneType' object has no attribute 'find'\n",
      "Error processing Black orchid: 'NoneType' object has no attribute 'find'\n",
      "Error processing Lignum vitae: 'NoneType' object has no attribute 'find'\n",
      "Error processing Others: 'NoneType' object has no attribute 'find'\n",
      "Error processing Ceibo: 'NoneType' object has no attribute 'find'\n",
      "Error processing Kantuta: 'NoneType' object has no attribute 'find'\n",
      "Error processing Mburucuy√°: 'NoneType' object has no attribute 'find'\n",
      "Error processing Ceibo: 'NoneType' object has no attribute 'find'\n",
      "Error processing Apple blossom: 'NoneType' object has no attribute 'find'\n",
      "Error processing Mock orange: 'NoneType' object has no attribute 'find'\n",
      "Error processing Wild rose: 'NoneType' object has no attribute 'find'\n",
      "Error processing Goldenrod: 'NoneType' object has no attribute 'find'\n",
      "Error processing Tassel: 'NoneType' object has no attribute 'find'\n",
      "Error processing Black-eyed susan: 'NoneType' object has no attribute 'find'\n",
      "Error processing Hawthorn: 'NoneType' object has no attribute 'find'\n",
      "Error processing Goldenrod: 'NoneType' object has no attribute 'find'\n",
      "Error processing Sagebrush: 'NoneType' object has no attribute 'find'\n",
      "Error processing Violet: 'NoneType' object has no attribute 'find'\n",
      "Error processing Violet: 'NoneType' object has no attribute 'find'\n",
      "Error processing American dogwood: 'NoneType' object has no attribute 'find'\n",
      "Error processing Wood violet: 'NoneType' object has no attribute 'find'\n",
      "Error processing Indian paintbrush: 'NoneType' object has no attribute 'find'\n",
      "Enhanced files saved as national_flowers_enhanced.csv and state_flowers_enhanced.csv.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_wikipedia_data(flower_name):\n",
    "    \"\"\"Fetch scientific name, an image URL, and symbolism from a flower's Wikipedia page.\"\"\"\n",
    "    search_url = f\"https://en.wikipedia.org/wiki/{flower_name.replace(' ', '_')}\"\n",
    "    data = {\n",
    "        \"Scientific Name\": \"Not found\",\n",
    "        \"Image URL\": \"Not found\",\n",
    "        \"Symbolism\": \"\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(search_url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            # Scientific Name\n",
    "            infobox = soup.find('table', {'class': 'infobox'})\n",
    "            if infobox:\n",
    "                scientific_name = infobox.find('i')\n",
    "                if scientific_name:\n",
    "                    data[\"Scientific Name\"] = scientific_name.text\n",
    "            # Image URL\n",
    "            image = infobox.find('img')\n",
    "            if image:\n",
    "                data[\"Image URL\"] = \"https:\" + image['src']\n",
    "            # Symbolism\n",
    "            headers = soup.find_all('span', {'class': 'mw-headline'})\n",
    "            for header in headers:\n",
    "                if 'symbolism' in header.text.lower():\n",
    "                    next_node = header.parent.find_next_sibling()\n",
    "                    if next_node and next_node.name in ['p', 'ul']:\n",
    "                        data[\"Symbolism\"] = next_node.text.strip()\n",
    "                    break\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {flower_name}: {str(e)}\")\n",
    "        return data\n",
    "\n",
    "def process_flowers(file_path, location_type):\n",
    "    \"\"\"Process flower data to add scientific names, images, and symbolism.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Flowers'] = df['Flower'].str.split(' and |,| or ')  # Split entries with multiple flowers\n",
    "    df = df.explode('Flowers').reset_index(drop=True)  # Create a new row for each flower\n",
    "    df['Flowers'] = df['Flowers'].str.strip().str.capitalize()  # Standardize capitalization\n",
    "    \n",
    "    # Fetch data from Wikipedia\n",
    "    wiki_data = df['Flowers'].apply(fetch_wikipedia_data).apply(pd.Series)\n",
    "    df = pd.concat([df, wiki_data], axis=1)\n",
    "    \n",
    "    # Clean up DataFrame\n",
    "    df.drop('Flower', axis=1, inplace=True)\n",
    "    df.rename(columns={'Flowers': 'Flower'}, inplace=True)\n",
    "    output_path = f\"{location_type}_flowers_enhanced.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    return output_path\n",
    "\n",
    "# Process each CSV\n",
    "output_national = process_flowers('national_flowers.csv', 'national')\n",
    "output_state = process_flowers('us_state_flowers.csv', 'state')\n",
    "\n",
    "print(f\"Enhanced files saved as {output_national} and {output_state}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8acd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
